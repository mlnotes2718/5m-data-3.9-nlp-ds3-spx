{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b66ea12",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be552c",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656570d",
   "metadata": {},
   "source": [
    "### Text Classification for Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00a3e8",
   "metadata": {},
   "source": [
    "In this assignment, you will build a text classification model using Naive Bayes to classify SMS messages as spam or ham (non-spam). You will implement text preprocessing techniques and use the Vector Space Model (TF-IDF) to represent the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236402f9",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf71a1",
   "metadata": {},
   "source": [
    "You will be using the SMS Spam Collection dataset, which contains a set of SMS messages that have been labeled as either spam or ham (legitimate). This dataset is available through several Python libraries or can be downloaded directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf14ee",
   "metadata": {},
   "source": [
    "#### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6813bb",
   "metadata": {},
   "source": [
    "1. **Text Preprocessing**:\n",
    "\n",
    "   - Load the dataset\n",
    "   - Implement tokenization\n",
    "   - Apply stemming or lemmatization\n",
    "   - Remove stopwords\n",
    "\n",
    "2. **Feature Extraction**:\n",
    "\n",
    "   - Use TF-IDF vectorization to convert the text data into numerical features\n",
    "   - Explore the most important features for spam and ham categories\n",
    "\n",
    "3. **Classification**:\n",
    "\n",
    "   - Split the data into training and testing sets\n",
    "   - Train a Multinomial Naive Bayes classifier\n",
    "   - Evaluate the model using appropriate metrics (accuracy, precision, recall, F1-score)\n",
    "   - Create a confusion matrix to visualize the results\n",
    "\n",
    "4. **Analysis**:\n",
    "   - Analyze false positives and false negatives\n",
    "   - Identify characteristics of messages that are frequently misclassified\n",
    "   - Suggest improvements to your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec92c8",
   "metadata": {},
   "source": [
    "#### Starter Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43bf450b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79173630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exist, skip download.\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "data_path = Path('./notebooks/data')\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)\n",
    "    print(f'Data folder not exists. Create folder')\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
    "\n",
    "file_path = Path('./notebooks/data/sms.tsv')\n",
    "\n",
    "if file_path.exists():\n",
    "    print('File already exist, skip download.')\n",
    "else:\n",
    "    try:\n",
    "        print('Downloading Data File')\n",
    "        urlretrieve(url, file_path)\n",
    "        print('Download completed')\n",
    "    except Exception as e:\n",
    "        print(\"Error downloading file. Please check if the file exist at the location:\", url)\n",
    "        print(\"Please also check if Internet connection is present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2c7e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# Convert data to Pandas dataframe\n",
    "sms_data = pd.read_csv('sms.tsv', sep='\\t', header=None, names=['label', 'message'])\n",
    "print(sms_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e33086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check data distribution\n",
    "print(sms_data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc58a0",
   "metadata": {},
   "source": [
    "**The target label are highly skewed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f94360",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data['target'] = sms_data['label'].map({'ham':0,'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2a3d822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  target\n",
       "0   ham  Go until jurong point, crazy.. Available only ...       0\n",
       "1   ham                      Ok lar... Joking wif u oni...       0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...       1\n",
       "3   ham  U dun say so early hor... U c already then say...       0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581f7a1",
   "metadata": {},
   "source": [
    "### Tokenization / Stemming / Lemmatization and Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd7e02a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement text preprocessing\n",
    "# - Tokenization\n",
    "# - Stemming/Lemmatization\n",
    "# - Stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7cfe03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aiml/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/aiml/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/aiml/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/aiml/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/aiml/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aiml/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK package \n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f10e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize \n",
    "snowball = SnowballStemmer(language='english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words  = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f974d62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define preprocessing function\n",
    "def tokenize_filter_stem_lemma(text):\n",
    "    # tokenize & lowercase\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # remove stop-words & non-alpha tokens\n",
    "    filtered = [tok for tok in tokens \n",
    "                if tok.isalpha() and tok not in stop_words]\n",
    "    # stem and lemmatize\n",
    "    stems  = [snowball.stem(tok)     for tok in filtered]\n",
    "    lemmas = [lemmatizer.lemmatize(tok) for tok in filtered]\n",
    "    # return all three processed text\n",
    "    return {\n",
    "        'tokens': filtered,\n",
    "        'stems':   stems,\n",
    "        'lemmas':  lemmas\n",
    "    }\n",
    "\n",
    "# 4. Apply to DF column\n",
    "processed = sms_data['message'].apply(tokenize_filter_stem_lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be7ecbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       {'tokens': ['go', 'jurong', 'point', 'crazy', ...\n",
       "1       {'tokens': ['ok', 'lar', 'joking', 'wif', 'u',...\n",
       "2       {'tokens': ['free', 'entry', 'wkly', 'comp', '...\n",
       "3       {'tokens': ['u', 'dun', 'say', 'early', 'hor',...\n",
       "4       {'tokens': ['nah', 'think', 'goes', 'usf', 'li...\n",
       "                              ...                        \n",
       "5567    {'tokens': ['time', 'tried', 'contact', 'u', '...\n",
       "5568    {'tokens': ['ü', 'b', 'going', 'esplanade', 'f...\n",
       "5569    {'tokens': ['pity', 'mood', 'suggestions'], 's...\n",
       "5570    {'tokens': ['guy', 'bitching', 'acted', 'like'...\n",
       "5571    {'tokens': ['rofl', 'true', 'name'], 'stems': ...\n",
       "Name: message, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bd1c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expand into separate columns\n",
    "sms_data = pd.concat(\n",
    "    [sms_data,\n",
    "     pd.DataFrame(list(processed))],\n",
    "    axis=1\n",
    ")\n",
    "sms_data['clean_text'] = sms_data['lemmas'].apply(lambda toks: ' '.join(toks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3016c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stems</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>[free, entri, wkli, comp, win, fa, cup, final,...</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "      <td>[nah, think, goe, usf, live, around, though]</td>\n",
       "      <td>[nah, think, go, usf, life, around, though]</td>\n",
       "      <td>nah think go usf life around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>1</td>\n",
       "      <td>[time, tried, contact, u, pound, prize, claim,...</td>\n",
       "      <td>[time, tri, contact, u, pound, prize, claim, e...</td>\n",
       "      <td>[time, tried, contact, u, pound, prize, claim,...</td>\n",
       "      <td>time tried contact u pound prize claim easy ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>0</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>[ü, b, go, esplanad, fr, home]</td>\n",
       "      <td>[ü, b, going, esplanade, fr, home]</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[pity, mood, suggestions]</td>\n",
       "      <td>[piti, mood, suggest]</td>\n",
       "      <td>[pity, mood, suggestion]</td>\n",
       "      <td>pity mood suggestion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>[guy, bitch, act, like, interest, buy, someth,...</td>\n",
       "      <td>[guy, bitching, acted, like, interested, buyin...</td>\n",
       "      <td>guy bitching acted like interested buying some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>0</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  target  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...       0   \n",
       "1      ham                      Ok lar... Joking wif u oni...       0   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...       1   \n",
       "3      ham  U dun say so early hor... U c already then say...       0   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...       0   \n",
       "...    ...                                                ...     ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...       1   \n",
       "5568   ham               Will ü b going to esplanade fr home?       0   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...       0   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...       0   \n",
       "5571   ham                         Rofl. Its true to its name       0   \n",
       "\n",
       "                                                 tokens  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4        [nah, think, goes, usf, lives, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [time, tried, contact, u, pound, prize, claim,...   \n",
       "5568                 [ü, b, going, esplanade, fr, home]   \n",
       "5569                          [pity, mood, suggestions]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                                  stems  \\\n",
       "0     [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                          [ok, lar, joke, wif, u, oni]   \n",
       "2     [free, entri, wkli, comp, win, fa, cup, final,...   \n",
       "3         [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4          [nah, think, goe, usf, live, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [time, tri, contact, u, pound, prize, claim, e...   \n",
       "5568                     [ü, b, go, esplanad, fr, home]   \n",
       "5569                              [piti, mood, suggest]   \n",
       "5570  [guy, bitch, act, like, interest, buy, someth,...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                                 lemmas  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, wkly, comp, win, fa, cup, final,...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4           [nah, think, go, usf, life, around, though]   \n",
       "...                                                 ...   \n",
       "5567  [time, tried, contact, u, pound, prize, claim,...   \n",
       "5568                 [ü, b, going, esplanade, fr, home]   \n",
       "5569                           [pity, mood, suggestion]   \n",
       "5570  [guy, bitching, acted, like, interested, buyin...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                             clean_text  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry wkly comp win fa cup final tkts may...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4                   nah think go usf life around though  \n",
       "...                                                 ...  \n",
       "5567  time tried contact u pound prize claim easy ca...  \n",
       "5568                        ü b going esplanade fr home  \n",
       "5569                               pity mood suggestion  \n",
       "5570  guy bitching acted like interested buying some...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5572 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e34bb",
   "metadata": {},
   "source": [
    "### TF-IDF and Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c70d14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply TF-IDF vectorization\n",
    "# TODO: Split data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9067ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sms_data[\"clean_text\"]\n",
    "y = sms_data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2304f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c244d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.9, min_df=5, ngram_range=(1,2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf  = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac8134",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d565cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a Multinomial Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91e37257",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_pred = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2877858",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'message': X_test,\n",
    "    'true_label': y_test,\n",
    "    'pred_label': y_pred\n",
    "}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14835533",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ad7a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffcc67c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "     0    1\n",
      "0  953    2\n",
      "1   24  136 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "cm_df = pd.DataFrame(cm, index=clf.classes_, columns=clf.classes_)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b080768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       955\n",
      "           1       0.99      0.85      0.91       160\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compute and display the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d5997",
   "metadata": {},
   "source": [
    "### Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dcee15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7b61b",
   "metadata": {},
   "source": [
    "**There are 2 sms that are predicted as spam but it did not turn out as spam. There are 24 sms that are actually spam but it was not classified as spam.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d50dcd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = results[\n",
    "    (results['pred_label'] == 1) & \n",
    "    (results['true_label'] == 0)\n",
    "]\n",
    "\n",
    "# False negatives: model predicted ham (0) but it was spam (1)\n",
    "false_negatives = results[\n",
    "    (results['pred_label'] == 0) & \n",
    "    (results['true_label'] == 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8747fb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>currently scotland</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>free call</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                message  true_label  pred_label\n",
       "407  currently scotland           0           1\n",
       "978           free call           0           1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96d79d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>hi sue year old work lapdancer love sex text l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>yes place town meet exciting adult single uk t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>new message call</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>email alertfrom jeri stewartsize prescripiton ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>send logo ur lover name joined heart txt love ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>next amazing xxx video sent enjoy one vid enou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>people dogging area call join like minded guy ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>dear voucher holder next meal u use following ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>realize year thousand old lady running around ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>missed call alert number called left message</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>mila blonde new uk look sex uk guy u like fun ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>let send free anonymous masked message im send...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>wml c</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>yes place town meet exciting adult single uk t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>oh god found number glad text back xafter msg ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>fantasy football back tv go sky gamestar sky a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>got take take part wrc rally oz u lucozade ene...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>latest news police station toilet stolen cop n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>guess somebody know secretly fancy wan na find...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>ur balance ur next question sang girl answer t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>sale arsenal dartboard good condition double t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>hi ya babe x u bout scammer getting smart thou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>bank granite issue explosive pick member nasda...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>send logo ur lover name joined heart txt love ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message  true_label  \\\n",
       "83    hi sue year old work lapdancer love sex text l...           1   \n",
       "181   yes place town meet exciting adult single uk t...           1   \n",
       "222                                    new message call           1   \n",
       "307   email alertfrom jeri stewartsize prescripiton ...           1   \n",
       "367   send logo ur lover name joined heart txt love ...           1   \n",
       "425   next amazing xxx video sent enjoy one vid enou...           1   \n",
       "458   people dogging area call join like minded guy ...           1   \n",
       "521   dear voucher holder next meal u use following ...           1   \n",
       "538   realize year thousand old lady running around ...           1   \n",
       "549        missed call alert number called left message           1   \n",
       "552   mila blonde new uk look sex uk guy u like fun ...           1   \n",
       "576   let send free anonymous masked message im send...           1   \n",
       "617                                               wml c           1   \n",
       "675   yes place town meet exciting adult single uk t...           1   \n",
       "766   oh god found number glad text back xafter msg ...           1   \n",
       "775   fantasy football back tv go sky gamestar sky a...           1   \n",
       "777   got take take part wrc rally oz u lucozade ene...           1   \n",
       "879   latest news police station toilet stolen cop n...           1   \n",
       "899   guess somebody know secretly fancy wan na find...           1   \n",
       "906   ur balance ur next question sang girl answer t...           1   \n",
       "970   sale arsenal dartboard good condition double t...           1   \n",
       "990   hi ya babe x u bout scammer getting smart thou...           1   \n",
       "1084  bank granite issue explosive pick member nasda...           1   \n",
       "1104  send logo ur lover name joined heart txt love ...           1   \n",
       "\n",
       "      pred_label  \n",
       "83             0  \n",
       "181            0  \n",
       "222            0  \n",
       "307            0  \n",
       "367            0  \n",
       "425            0  \n",
       "458            0  \n",
       "521            0  \n",
       "538            0  \n",
       "549            0  \n",
       "552            0  \n",
       "576            0  \n",
       "617            0  \n",
       "675            0  \n",
       "766            0  \n",
       "775            0  \n",
       "777            0  \n",
       "879            0  \n",
       "899            0  \n",
       "906            0  \n",
       "970            0  \n",
       "990            0  \n",
       "1084           0  \n",
       "1104           0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75837a5",
   "metadata": {},
   "source": [
    "**The following are text that are spam but wrongly classified as non-spam.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75f01202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi sue year old work lapdancer love sex text live bedroom text sue textoperator\n",
      "yes place town meet exciting adult single uk txt chat\n",
      "new message call\n",
      "email alertfrom jeri stewartsize prescripiton drvgsto listen email call\n",
      "send logo ur lover name joined heart txt love mobno eg love adam eve yahoo txtno ad\n",
      "next amazing xxx video sent enjoy one vid enough text back keyword get next video\n",
      "people dogging area call join like minded guy arrange evening minapn\n",
      "dear voucher holder next meal u use following link pc enjoy dining experiencehttp\n",
      "realize year thousand old lady running around tattoo\n",
      "missed call alert number called left message\n",
      "mila blonde new uk look sex uk guy u like fun text mtalk increment\n",
      "let send free anonymous masked message im sending message see potential abuse\n",
      "wml c\n",
      "yes place town meet exciting adult single uk txt chat\n",
      "oh god found number glad text back xafter msg cst std ntwk chg\n",
      "fantasy football back tv go sky gamestar sky active play dream team scoring start saturday register sky opt\n",
      "got take take part wrc rally oz u lucozade energy text rally le see pack itcould u\n",
      "latest news police station toilet stolen cop nothing go\n",
      "guess somebody know secretly fancy wan na find give u call landline\n",
      "ur balance ur next question sang girl answer txt ur answer good luck\n",
      "sale arsenal dartboard good condition double treble\n",
      "hi ya babe x u bout scammer getting smart though regular vodafone respond get prem rate no used also beware\n",
      "bank granite issue explosive pick member nasdaq symbol cdgt per\n",
      "send logo ur lover name joined heart txt love mobno eg love adam eve yahoo txtno ad\n"
     ]
    }
   ],
   "source": [
    "for i in false_negatives['message']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a97c8",
   "metadata": {},
   "source": [
    "### Conclusion / Further Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428389fe",
   "metadata": {},
   "source": [
    "**It depends on the cost of getting spam and the cost of missing email that are not spam. The higher cost of either getting spam or missing non-spam message will affect our decision and focus. If the cost of missing important sms is high, then we should focus on precision. If the cost of getting the spam is high, then we should focus on recall.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f1550a",
   "metadata": {},
   "source": [
    "**There are several ways to improve the model:**\n",
    "\n",
    "- **We can use grid search to fine the optional parameters and also using recall or precision as the scoring metrics.**\n",
    "- **We can adjust the probability of the classification to lower than 0.5 in order to capture more spam or we raise the threshold to higher then 0.5 to avoid missing non-spam message.**\n",
    "- **We can resample the training data to focus more on spam data and less on non-spam data.**\n",
    "- **We can experiment different ngram parameters to get the best performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec2fa0e",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
