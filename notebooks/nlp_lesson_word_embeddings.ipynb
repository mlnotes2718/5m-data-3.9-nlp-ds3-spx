{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "mRYeqNj62i_G",
      "metadata": {
        "id": "mRYeqNj62i_G"
      },
      "source": [
        "## Welcome! Please take note of instructions below:\n",
        "\n",
        "If this is the first time you visited this Colab notebook after clicking a link, you will see \"Cannot will not be saved\" message at the top of the Colab menu.\n",
        "\n",
        "To save a local copy with edit access, choose File -> Save a copy in Drive\n",
        "\n",
        "It will create a copy of the Colab notebook in your Google Drive storage with edit access."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "GuYjyL2Rdd3_",
      "metadata": {
        "id": "GuYjyL2Rdd3_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim>=4.3.2\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim>=4.3.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim>=4.3.2) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim>=4.3.2) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim>=4.3.2) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "### Install gensim.\n",
        "### After it is installed, restart kernel. To do so, in Google Colab menu above, choose Runtime -> Restart session\n",
        "!pip install -U \"gensim>=4.3.2\""
      ]
    },
    {
      "attachments": {
        "vector.png": {
          "image/png": "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"
        }
      },
      "cell_type": "markdown",
      "id": "4d386884-fe61-41d7-9bb5-9ee3cd0abaf8",
      "metadata": {
        "id": "4d386884-fe61-41d7-9bb5-9ee3cd0abaf8"
      },
      "source": [
        "# Word Embeddings\n",
        "\n",
        "## What are Word Embeddings?\n",
        "\n",
        "Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation. They are a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging NLP problems.\n",
        "\n",
        "In essence, word embeddings are a form of word representation that bridges the human understanding of language to that of a machine. They are mappings to a high-dimensional space, where words that have similar meanings are located in close proximity to one another.\n",
        "\n",
        "## Why Use Word Embeddings?\n",
        "\n",
        "Traditional language models often represent words as one-hot encoded vectors where each word is represented by a vector with a dimensionality equal to the size of the vocabulary. The main issue with this approach is that the resulting vectors are sparse and do not capture any information about word relationships.\n",
        "\n",
        "Word embeddings address this by providing a dense representation where similar words have a similar encoding. Importantly, word embeddings can capture nuances about words, such as their semantic and syntactic information.\n",
        "\n",
        "## Word2Vec\n",
        "\n",
        "Word2Vec is a popular algorithm to produce word embeddings by training a neural network with a single hidden layer. Word2Vec comes with two model architectures:\n",
        "\n",
        "### Architecture (CBOW and Skip-gram)\n",
        "\n",
        "- **Continuous Bag of Words (CBOW)**: The CBOW model predicts the current word based on the context, and the context is represented as a bag of words. Hence, the order of words in the context does not influence prediction (bag of words model).\n",
        "\n",
        "- **Skip-gram**: The Skip-gram model works in the reverse manner, it tries to predict the context for a given word.\n",
        "\n",
        "### Training Word2Vec\n",
        "\n",
        "The Word2Vec model is trained with either one of these architectures, each of which has the objective to learn word vector representations that are good at predicting their context in the input corpus.\n",
        "\n",
        "For a given word $ w_I $ and its context $ w_O $ in the corpus, the objective of the Skip-gram model is to maximize the following log probability:\n",
        "\n",
        "$$ \\frac{1}{T} \\sum_{t=1}^{T} \\sum_{-c \\leq j \\leq c, j \\neq 0} \\log p(w_{t+j} | w_t) $$\n",
        "\n",
        "where $ c $ is the size of the training context (which can be a function of the center word $ w_t $). The $ p(w_{t+j} | w_t) $ is defined using the softmax function:\n",
        "\n",
        "$$ p(w_O | w_I) = \\frac{\\exp({v'_{w_O}}^T v_{w_I})}{\\sum_{w=1}^{W} \\exp({v'_w}^T v_{w_I})} $$\n",
        "\n",
        "where $ v_w $ and $ v'_w $ are the \"input\" and \"output\" vector representations of $ w $, and $ W $ is the number of words in the vocabulary.\n",
        "\n",
        "### Applications\n",
        "\n",
        "One of the fascinating properties of Word2Vec embeddings is their ability to capture analogies and relationships between words. The classic example often cited to demonstrate this is the relationship between \"man\" and \"woman,\" and \"king\" and \"queen.\"\n",
        "\n",
        "Word2Vec can capture these relationships because it learns vector representations of words in such a way that the geometric relationships between the vectors capture semantic relationships between the words. For instance, the difference between the vectors for \"man\" and \"woman\" often encodes the concept of gender. Similarly, the difference between \"king\" and \"queen\" captures the same concept of gender.\n",
        "\n",
        "![vector.png](attachment:vector.png)\n",
        "![word2vec](https://drive.google.com/uc?id=1lpFJylhiveWa7j6sXwoSkA0MSBDK485K)\n",
        "\n",
        "In practice, this means that if we take the vector for \"king,\" subtract the vector for \"man,\" and then add the vector for \"woman,\" we end up with a vector that is close to the vector for \"queen.\" Mathematically, this relationship can be represented as:\n",
        "\n",
        "$$ \\textbf{vector}('king') - \\textbf{vector}('man') + \\textbf{vector}('woman') \\approx \\textbf{vector}('queen') $$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a58613-6e36-452b-9424-9971226313a2",
      "metadata": {
        "id": "95a58613-6e36-452b-9424-9971226313a2"
      },
      "source": [
        "Let's use the `20 Newsgroups` dataset, which is a collection of approximately 20,000 newsgroup documents, partitioned across 20 different newsgroups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f0c8cbdf-240c-46fe-9604-6ef9a7435b43",
      "metadata": {
        "id": "f0c8cbdf-240c-46fe-9604-6ef9a7435b43"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "edadcf3b-2519-4a2c-a9bb-46fd3fa662a5",
      "metadata": {
        "id": "edadcf3b-2519-4a2c-a9bb-46fd3fa662a5"
      },
      "outputs": [],
      "source": [
        "# Fetch the 20 newsgroups dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "43098938-fe4f-4164-8379-53e24e6a4a25",
      "metadata": {
        "id": "43098938-fe4f-4164-8379-53e24e6a4a25"
      },
      "outputs": [],
      "source": [
        "# Preprocess the text using gensim's simple_preprocess\n",
        "# This will tokenize the text, lowercasing, and remove punctuation\n",
        "corpus = [simple_preprocess(doc) for doc in newsgroups_train.data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "187622c9-dec4-4276-bf9d-e6ffccbc4a59",
      "metadata": {
        "id": "187622c9-dec4-4276-bf9d-e6ffccbc4a59"
      },
      "outputs": [],
      "source": [
        "# Train the Word2Vec model\n",
        "model = Word2Vec(corpus, vector_size=100, window=5, min_count=5, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b8d24198-9613-489f-ab53-8674bc4719a1",
      "metadata": {
        "id": "b8d24198-9613-489f-ab53-8674bc4719a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most similar words to 'computer':\n",
            "electronics: 0.7525\n",
            "network: 0.7322\n",
            "programming: 0.7065\n",
            "software: 0.6977\n",
            "project: 0.6977\n",
            "graphics: 0.6971\n",
            "tech: 0.6888\n",
            "computers: 0.6815\n",
            "library: 0.6805\n",
            "workstation: 0.6736\n"
          ]
        }
      ],
      "source": [
        "# Explore the model\n",
        "# Let's find the most similar words to 'computer'\n",
        "similar_words = model.wv.most_similar('computer', topn=10)\n",
        "print(\"Most similar words to 'computer':\")\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"{word}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aa836c66-60af-48ef-b586-a40f517954ea",
      "metadata": {
        "id": "aa836c66-60af-48ef-b586-a40f517954ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most similar words to 'car':\n",
            "bike: 0.8517\n",
            "tires: 0.7578\n",
            "battery: 0.7203\n",
            "engine: 0.7116\n",
            "driving: 0.7054\n",
            "seat: 0.7045\n",
            "helmet: 0.6904\n",
            "oil: 0.6813\n",
            "brake: 0.6762\n",
            "dealer: 0.6747\n"
          ]
        }
      ],
      "source": [
        "similar_words = model.wv.most_similar('car', topn=10)\n",
        "print(\"Most similar words to 'car':\")\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"{word}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51da3ca4-9beb-4bad-adb1-bb42771a9971",
      "metadata": {
        "id": "51da3ca4-9beb-4bad-adb1-bb42771a9971"
      },
      "source": [
        "# Advanced Embeddings\n",
        "\n",
        "## GloVe\n",
        "\n",
        "GloVe is an unsupervised learning algorithm for obtaining vector representations of words. It stands for \"Global Vectors for Word Representation,\" and it is specifically designed to capture global word-word co-occurrence statistics from a corpus. The resulting representations showcase interesting linear substructures of the word vector space.\n",
        "\n",
        "### How GloVe Works\n",
        "\n",
        "The GloVe model is trained on the non-zero elements in a word-word co-occurrence matrix, which tabulates how frequently words co-occur with one another in a given corpus. Instead of using window-based co-occurrence, GloVe constructs an explicit word-context or word-word co-occurrence matrix using statistics across the whole text corpus.\n",
        "\n",
        "The model then uses matrix factorization techniques to yield a word vector space, where the difference between any two word vectors aims to approximate the logarithm of the words' probability of co-occurrence.\n",
        "\n",
        "Given a co-occurrence matrix $X$, where $X_{ij}$ denotes the number of times word $j$ occurs in the context of word $i$, the GloVe model aims to learn a vector $w_i$ for each word $i$ such that the dot product $w_i^T w_j$ is proportional to the logarithm of $X_{ij}$.\n",
        "\n",
        "The training objective of GloVe is:\n",
        "\n",
        "$$ J = \\sum_{i,j=1}^V f(X_{ij}) (w_i^T w_j + b_i + b_j - \\log X_{ij})^2 $$\n",
        "\n",
        "where $V$ is the size of the vocabulary, $b_i$ and $b_j$ are scalar bias terms for words $i$ and $j$, and $f$ is a weighting function that helps prevent learning from large co-occurrence counts.\n",
        "\n",
        "## FastText\n",
        "\n",
        "FastText is another word embedding method that extends Word2Vec to consider subword information. This means that it takes into account the internal structure of words while learning word representations. FastText is particularly useful for languages with rich morphology and for understanding words outside the training vocabulary.\n",
        "\n",
        "### How FastText Works\n",
        "\n",
        "FastText represents each word as a bag of character n-grams, in addition to the word itself. This means that the word \"apple\" with $n=3$ would be represented as the following n-grams: \"<ap\", \"app\", \"ppl\", \"ple\", \"le>\" (where \"<\" and \">\" are added to denote the beginning and end of the word, respectively).\n",
        "\n",
        "The model then learns vector representations for these character n-grams, and the word vector is computed as the sum of the n-gram vectors. This allows FastText to produce representations for words not seen during training by summing the vectors of its component n-grams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "09ce6c70-18fc-4371-a8eb-3caff7a77a55",
      "metadata": {
        "id": "09ce6c70-18fc-4371-a8eb-3caff7a77a55"
      },
      "outputs": [],
      "source": [
        "from gensim.models.fasttext import FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d3b9b318-fbc0-4a6f-9088-8efb6bbffb5f",
      "metadata": {
        "id": "d3b9b318-fbc0-4a6f-9088-8efb6bbffb5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12579282, 16476320)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the FastText model\n",
        "# The `vector_size` parameter specifies the dimensionality of the word vectors,\n",
        "# `window` specifies the maximum distance between the current and predicted word within a sentence\n",
        "# `min_count` specifies the minimum count of words to consider\n",
        "# `workers` specifies the number of worker threads to train the model.\n",
        "ft_model = FastText(vector_size=100, window=5, min_count=5, workers=4)\n",
        "ft_model.build_vocab(corpus_iterable=corpus)\n",
        "ft_model.train(corpus_iterable=corpus, total_examples=len(corpus), epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8ba15ef9-aaeb-44b7-a5fc-4b03806de2b1",
      "metadata": {
        "id": "8ba15ef9-aaeb-44b7-a5fc-4b03806de2b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most similar words to 'computer':\n",
            "microcomputer: 0.9613\n",
            "supercomputer: 0.9552\n",
            "compute: 0.9279\n",
            "computrac: 0.9028\n",
            "compusa: 0.8801\n",
            "computers: 0.8751\n",
            "compuadd: 0.8655\n",
            "computes: 0.8651\n",
            "compulsion: 0.8642\n",
            "compulink: 0.8619\n"
          ]
        }
      ],
      "source": [
        "# Let's find the most similar words to 'computer'\n",
        "similar_words = ft_model.wv.most_similar('computer', topn=10)\n",
        "print(\"Most similar words to 'computer':\")\n",
        "for word, similarity in similar_words:\n",
        "    print(f\"{word}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d911d3ca-f7b6-4291-9902-2b1a7dd9d6ce",
      "metadata": {
        "id": "d911d3ca-f7b6-4291-9902-2b1a7dd9d6ce"
      },
      "source": [
        "# Text Classification with Naive Bayes\n",
        "\n",
        "Naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong independence assumptions between the features. They are among the most straightforward and effective algorithms used in machine learning and natural language processing (NLP) for text classification tasks, such as spam filtering and sentiment analysis.\n",
        "\n",
        "## Understanding Naive Bayes\n",
        "\n",
        "Bayes' theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For a class variable \\(y\\) and a dependent feature vector \\(x_1\\) through \\(x_n\\), Bayes' theorem states the following relationship:\n",
        "\n",
        "$$ P(y \\mid x_1, \\ldots, x_n) = \\frac{P(y) P(x_1, \\ldots, x_n \\mid y)}{P(x_1, \\ldots, x_n)} $$\n",
        "\n",
        "In the Naive Bayes classification, we are interested in finding the class with the highest probability, given the features. The \"naive\" assumption of conditional independence between every pair of features given the value of the class variable simplifies the computation, as follows:\n",
        "\n",
        "$$ P(y \\mid x_1, \\ldots, x_n) \\propto P(y) \\prod_{i=1}^n P(x_i \\mid y) $$\n",
        "\n",
        "Since we are only interested in the class with the maximum probability, we can ignore the denominator and use the following classification rule:\n",
        "\n",
        "$$ \\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^n P(x_i \\mid y) $$\n",
        "\n",
        "## Naive Bayes in NLP\n",
        "\n",
        "In NLP, Naive Bayes classifiers are commonly applied to text classification problems. When dealing with text, the features are usually the frequency or presence of words. For example, in a spam filtering application, the features might be the presence or frequency of specific words or sequences of words in an email.\n",
        "\n",
        "### Multinomial Naive Bayes\n",
        "\n",
        "The Multinomial Naive Bayes classifier is a specific instance of a Naive Bayes classifier which is widely used for document classification problems. It accounts for the number of occurrences of each word (term frequency) for classification.\n",
        "\n",
        "### Bernoulli Naive Bayes\n",
        "\n",
        "The Bernoulli Naive Bayes classifier is suitable when your feature vectors are binary (i.e., 0s and 1s). An example might be text classification with a 'bag of words' model where the 1s & 0s represent the presence or absence of a word in the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4094f210-d4c4-4e06-bc49-c932402f2810",
      "metadata": {
        "id": "4094f210-d4c4-4e06-bc49-c932402f2810"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0923eee0-df30-4ba5-b955-c4819240bcc5",
      "metadata": {
        "id": "0923eee0-df30-4ba5-b955-c4819240bcc5"
      },
      "outputs": [],
      "source": [
        "# Fetch the dataset\n",
        "categories = ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6b0a2518-2fd1-466b-bab9-682d11979c63",
      "metadata": {
        "id": "6b0a2518-2fd1-466b-bab9-682d11979c63"
      },
      "outputs": [],
      "source": [
        "# Create a pipeline that vectorizes the data then applies Multinomial Naive Bayes classifier\n",
        "model = make_pipeline(CountVectorizer(), MultinomialNB())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6cf77f68-4a39-4e9e-b077-1c17a7c9d666",
      "metadata": {
        "id": "6cf77f68-4a39-4e9e-b077-1c17a7c9d666"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;countvectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;multinomialnb&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
              "                ('multinomialnb', MultinomialNB())])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(newsgroups_train.data, newsgroups_train.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "92e9f771-6d26-428d-8c0a-e7d4618c6fac",
      "metadata": {
        "id": "92e9f771-6d26-428d-8c0a-e7d4618c6fac"
      },
      "outputs": [],
      "source": [
        "# Predict the categories of the test data\n",
        "predicted_categories = model.predict(newsgroups_test.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6920ff83-edde-4d2c-b17c-4f3ba91bc8dc",
      "metadata": {
        "id": "6920ff83-edde-4d2c-b17c-4f3ba91bc8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.92      0.90      0.91       319\n",
            "         comp.graphics       0.95      0.95      0.95       389\n",
            "               sci.med       0.96      0.91      0.93       396\n",
            "soc.religion.christian       0.91      0.97      0.94       398\n",
            "\n",
            "              accuracy                           0.93      1502\n",
            "             macro avg       0.93      0.93      0.93      1502\n",
            "          weighted avg       0.93      0.93      0.93      1502\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "print(classification_report(newsgroups_test.target, predicted_categories, target_names=newsgroups_test.target_names))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
